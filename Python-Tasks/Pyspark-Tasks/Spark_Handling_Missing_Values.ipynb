{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext(conf=SparkConf().setAppName(\"MyApp\").setMaster(\"local[2]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sqlContext.read.load(\"daily_weather.csv\",format=\"com.databricks.spark.csv\",header='true',inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+---------------------+\n",
      "|summary|            number| air_pressure_9am|      air_temp_9am|avg_wind_direction_9am|avg_wind_speed_9am|max_wind_direction_9am|max_wind_speed_9am|rain_accumulation_9am| rain_duration_9am|relative_humidity_9am|relative_humidity_3pm|\n",
      "+-------+------------------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+---------------------+\n",
      "|  count|              1095|             1092|              1090|                  1091|              1092|                  1092|              1091|                 1089|              1092|                 1095|                 1095|\n",
      "|   mean|             547.0|918.8825513138094| 64.93300141287072|     142.2355107005759|  5.50828424225493|    148.95351796516923| 7.019513529175272|  0.20307895225211126| 294.1080522756142|    34.24140205923536|    35.34472714825898|\n",
      "| stddev|316.24357700987383|3.184161180386833|11.175514003175877|     69.13785928889189|4.5528134655317185|     67.23801294602953| 5.598209170780958|   1.5939521253574893|1598.0787786601481|   25.472066802250055|   22.524079453587273|\n",
      "|    min|                 0|907.9900000000024|36.752000000000685|    15.500000000000046|  0.69345139999974|     28.89999999999991|1.1855782000000479|                  0.0|               0.0|    6.090000000001012|   5.3000000000006855|\n",
      "|    max|              1094|929.3200000000012| 98.90599999999992|                 343.4|23.554978199999763|    312.19999999999993| 29.84077959999996|    24.01999999999907|           17704.0|     92.6200000000002|     92.2500000000003|\n",
      "+-------+------------------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1090|\n",
      "|   mean| 64.93300141287072|\n",
      "| stddev|11.175514003175877|\n",
      "|    min|36.752000000000685|\n",
      "|    max| 98.90599999999992|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['air_temp_9am']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the null value rows in the dataset\n",
    "removeAllDf=df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1064"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeAllDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      air_temp_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1064|\n",
      "|   mean| 65.02260949558733|\n",
      "| stddev|11.168033449415704|\n",
      "|    min|36.752000000000685|\n",
      "|    max| 98.90599999999992|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "removeAllDf.describe(['air_temp_9am']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Mean value  after removing missing values\n",
    "\n",
    "from pyspark.sql.functions import avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 545.0018796992481\n",
      "air_pressure_9am 918.9031798641051\n",
      "air_temp_9am 65.02260949558733\n",
      "avg_wind_direction_9am 142.30675564934037\n",
      "avg_wind_speed_9am 5.48579305071369\n",
      "max_wind_direction_9am 148.48042413321315\n",
      "max_wind_speed_9am 6.999713658875691\n",
      "rain_accumulation_9am 0.18202347650615522\n",
      "rain_duration_9am 266.3936973996037\n",
      "relative_humidity_9am 34.07743985327709\n",
      "relative_humidity_3pm 35.14838093290533\n"
     ]
    }
   ],
   "source": [
    "imputeDf=df\n",
    "\n",
    "for x in imputeDf.columns:\n",
    "    \n",
    "    meanvalue=removeAllDf.agg(avg(x)).first()[0]\n",
    "    print(x,meanvalue)\n",
    "    imputeDf=imputeDf.na.fill(meanvalue,[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary| air_pressure_9am|\n",
      "+-------+-----------------+\n",
      "|  count|             1092|\n",
      "|   mean|918.8825513138094|\n",
      "| stddev|3.184161180386833|\n",
      "|    min|907.9900000000024|\n",
      "|    max|929.3200000000012|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary| air_pressure_9am|\n",
      "+-------+-----------------+\n",
      "|  count|             1095|\n",
      "|   mean|918.8826078303855|\n",
      "| stddev|3.179792514510735|\n",
      "|    min|907.9900000000024|\n",
      "|    max|929.3200000000012|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['air_pressure_9am']).show()\n",
    "imputeDf.describe(['air_pressure_9am']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+---------------------+\n",
      "|number|air_pressure_9am|air_temp_9am|avg_wind_direction_9am|avg_wind_speed_9am|max_wind_direction_9am|max_wind_speed_9am|rain_accumulation_9am|rain_duration_9am|relative_humidity_9am|relative_humidity_3pm|\n",
      "+------+----------------+------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+---------------------+\n",
      "|     0|               3|           5|                     4|                 3|                     3|                 4|                    6|                3|                    0|                    0|\n",
      "+------+----------------+------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
